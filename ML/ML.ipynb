{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning :\n",
    "\n",
    "Implement a suitable classical machine learning algorithm to detect characters in these signs and display detected\n",
    "text finally.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Algorithm:\n",
    "\n",
    "Step 1: Read Image using Opencv\n",
    "\n",
    "Step 2: Extract text from the image using Opencv Methods\n",
    "\n",
    "Step 3: Extract the character using masking method\n",
    "\n",
    "Step 4: Comparing the ground-truth and extracted image by using cosine similarity\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "import numpy as np\n",
    "import cv2\n",
    "from imutils import contours as sort_contour\n",
    "from scipy import spatial\n",
    "import glob\n",
    "import os\n",
    "import pandas as pd\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results {'Text0': {'ROI0': {'R': 0.999992952672644}, 'ROI1': {'_': 0.9842400830772055}, 'ROI2': {'E': 0.9999860599222188}, 'ROI3': {'S': 0.9999867589352665}, 'ROI4': {'T': 0.9999859038704109}}, 'Text1': {'ROI0': {}}, 'Text2': {'ROI0': {'M': 0.999994053100458}, 'ROI1': {'I': 0.9999930824283155, 'L': 0.9742207647254794, '_': 0.9742207647254794}, 'ROI2': {'L': 0.9999956937060123}, 'ROI3': {'E': 0.999991922036403}}, 'Text3': {'ROI0': {'+': 0.9999915388987497}, 'ROI1': {'_': 0.9886872400809098}, 'ROI2': {'+': 0.9999908160801005}}}\n"
     ]
    }
   ],
   "source": [
    "def similarity(ground_truth,predict):\n",
    "    \n",
    "    '''Comparing collect images for character with extracted images\"'''\n",
    "    reshape_size=(50,50)\n",
    "    x= cv2.resize(ground_truth,reshape_size,interpolation = cv2.INTER_LINEAR)\n",
    "    y= cv2.resize(predict,reshape_size,interpolation = cv2.INTER_LINEAR)\n",
    "    x,y= x.flatten()/255,y.flatten()/255  #normalization\n",
    "    sim = -1 * (spatial.distance.cosine(x, y) - 1)  #gives the cosine value for both vectors\n",
    "    return sim\n",
    "\n",
    "\n",
    "def character_extractor(word, path_name='NA'):\n",
    "    word_c=word.copy()\n",
    "    if word.shape[0]==0 or word.shape[1]==0:return word_c,{}\n",
    "    \n",
    "    Alphabets=\"ABCDEFGHIJKLMNOPQRSTUVWXYZ_+\"\n",
    "#     word=adjust_gamma(word)\n",
    "    mask=masking(word,np.array([0, 0, 164]),np.array([255, 255, 255]))\n",
    "    contours, hierarchy = cv2.findContours(mask,cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE) # finding contours for masked image\n",
    "    if contours:\n",
    "        contours, _ = sort_contour.sort_contours(contours, method=\"left-to-right\")\n",
    "    roi_count=0\n",
    "    dic={}\n",
    "    for c in contours:\n",
    "        dic['ROI'+str(roi_count)]={}\n",
    "        x,y,w,h = cv2.boundingRect(c)\n",
    "        predict=mask[y:y + h,x:x + w]\n",
    "         \n",
    "        if write:\n",
    "            path='./prepare_dataset/{}/roi_{}.jpg'.format(path_name,roi_count)\n",
    "            cv2.imwrite(path,predict)\n",
    "        else:    \n",
    "            for ch in Alphabets:\n",
    "                for ch_ls in glob.glob('./Character_Data/{}/*.jpg'.format(ch)):\n",
    "                    ground_truth=cv2.imread(ch_ls,0)\n",
    "                    sim= similarity(ground_truth,predict) \n",
    "                    '''0.97 is the threshold value given. If the cosine value is greater or equal to threshold value then\n",
    "                        the both images having similarity greater and equal to 97%.'''\n",
    "                    if sim >=0.97: \n",
    "                        dic['ROI'+str(roi_count)][ch]=sim     \n",
    "\n",
    "            cv2.rectangle(word_c, (x, y), (x + w, y + h), (0,0,255), 1)\n",
    "        \n",
    "        roi_count+=1 \n",
    "    return word_c,dic \n",
    "\n",
    "def adjust_gamma(image, gamma=1.1):\n",
    "    '''Used to adjust the brightness or gamma value of given image'''\n",
    "    invGamma = 1.0 / gamma\n",
    "    table = np.array([((i / 255.0) ** invGamma) * 255\n",
    "        for i in np.arange(0, 256)]).astype(\"uint8\")\n",
    "    return cv2.LUT(image, table)\n",
    "\n",
    "\n",
    "def masking(img,lower, upper):\n",
    "    '''Given image is masked to lower and upper value that is passed in the function. The lower and Upper\n",
    "       are extracted by using HSV values'''\n",
    "#     print(img.shape,\"masking\")\n",
    "    imgHSV = cv2.cvtColor(img,cv2.COLOR_BGR2HSV)             \n",
    "    mask = cv2.inRange(imgHSV,lower,upper)\n",
    "    return mask\n",
    "\n",
    "\n",
    "def preprocess(img,thresh_value=[145 ,145 ,145],name=\"NA\"):\n",
    "    global write\n",
    "#     print(img.shape,\"preprocess\")\n",
    "    \n",
    "    img_ori=img.copy()\n",
    "    sharpen_kernel = np.array([[-1,-1,-1], [-1,9,-1], [-1,-1,-1]])\n",
    "    img = cv2.filter2D(img, -1, sharpen_kernel)\n",
    "    white=[255,255,255]\n",
    "    blue=[255,0,0]\n",
    "    # finding the color and coverting the text color into blue\n",
    "    for y in range(0,img.shape[0]):\n",
    "        for x in range(0,img.shape[1]):\n",
    "            if img[y,x,0]>=thresh_value[0] and img[y,x,1]>thresh_value[1] and img[y,x,2]>thresh_value[2]:img[y,x] = blue\n",
    "            else:img[y,x] = white \n",
    "\n",
    "    mask=masking(img,np.array([0,0,0]),np.array([255,14,255]))\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_CROSS, (3,3))\n",
    "    mask = cv2.erode(mask,kernel,iterations = 1) #erosion\n",
    "    contours, hierarchy = cv2.findContours(mask,cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE) #to extract the text from mask image\n",
    "    if contours:\n",
    "        contours, _ = sort_contour.sort_contours(contours, method=\"left-to-right\")\n",
    "    \n",
    "    text_dic={}\n",
    "    text_count=0\n",
    "    for c in contours:\n",
    "        area = cv2.contourArea(c)\n",
    "        if (float(area)/float(mask.shape[0]*mask.shape[1]) > 0.02):\n",
    "            x,y,w,h = cv2.boundingRect(c)\n",
    "            if float(h)/float(mask.shape[0]) > 0.2 and float(h)/float(mask.shape[0]) < 0.7:\n",
    "                if write: #please make this variable 'True' if you want to save the data\n",
    "                    try:os.mkdir('./prepare_dataset/{}/{}'.format(name,text_count))\n",
    "                    except:pass \n",
    "                    img_ori[y:y + h,x:x + w],result=character_extractor(img_ori[y:y + h,x:x + w],path_name=\"{}/{}\".format(name,text_count))\n",
    "                else:img_ori[y:y + h,x:x + w],result=character_extractor(img_ori[y:y + h,x:x + w])\n",
    "                text_dic[\"Text\"+str(text_count)]=result\n",
    "                cv2.rectangle(img_ori, (x, y), (x + w, y + h), (0,255,0), 1)\n",
    "                text_count+=1\n",
    "    \n",
    "    return img_ori,mask,text_dic\n",
    "    \n",
    "    \n",
    "write=False    \n",
    "img=cv2.imread('./TestSet/2.png')\n",
    "h,w=img.shape[:2]\n",
    "img,mask,results=preprocess(img)\n",
    "\n",
    "print(\"Results\",results)\n",
    "\n",
    "\n",
    "cv2.imshow(\"img1\",img)\n",
    "cv2.imshow(\"mask\",mask)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make Character A-Z,1-9 Folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Alphanum=\"1234567890ABCDEFGHIJKLMNOPQRSTUVWXYZ_+\"\n",
    "# print(len(Alphabets))\n",
    "\n",
    "for i in Alphanum:\n",
    "    try:os.mkdir('./Character_Data/{}'.format(i))\n",
    "    except:pass    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thres=[[115 ,115 ,115],[145,145 ,145],[100 ,100 ,100],[150 ,150 ,150]] #threshold used to convert the text into blue \n",
    "\n",
    "\n",
    "write=True #to save the binary character images in respected folders\n",
    "for itr_thres in thres:\n",
    "    try:os.mkdir('./prepare_dataset/{}'.format(str(itr_thres)))\n",
    "    except:pass \n",
    "    for each_img in glob.glob('./TestSet/*.png'):\n",
    "        fol_1=each_img.split('\\\\')[-1].replace(\".\",\"_\")\n",
    "        try:os.mkdir('./prepare_dataset/{}/{}'.format(str(itr_thres),fol_1))\n",
    "        except:pass    \n",
    "        img=cv2.imread(each_img)\n",
    "        img,mask,results[str(itr_thres)]=preprocess(img,name=\"{}/{}\".format(str(itr_thres),fol_1), thresh_value=itr_thres)\n",
    "#         cv2.imshow(\"img1\",img)\n",
    "#         cv2.imshow(\"mask\",mask)\n",
    "#         cv2.waitKey(0)\n",
    "#         cv2.destroyAllWindows()\n",
    "        \n",
    "            \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving to excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analytic_txt(result_dic):\n",
    "    '''Find the maximum character extracted from the images.'''\n",
    "    text_analytics={}\n",
    "    final_res=[]\n",
    "    for thres_val,attr1 in result_dic.items():\n",
    "        for txt,attr2 in attr1.items():  \n",
    "            text_analytics[txt]=''\n",
    "            for roi_, attr3 in attr2.items():   \n",
    "                for wd in attr3.keys():\n",
    "                    text_analytics[txt]+=wd\n",
    "        final_res.append(text_analytics)  \n",
    "\n",
    "    lenght_ls=[]    \n",
    "    for len_ in final_res:\n",
    "        lenght_ls.append(len(len_.keys()))\n",
    "    select_text=final_res[lenght_ls.index(max(lenght_ls))]   \n",
    "    final_text=''\n",
    "    for ww in select_text.values():\n",
    "        final_text+=ww\n",
    "\n",
    "    return final_text     \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "write=False #Made into True only to collect the dataset\n",
    "data=[]\n",
    "\n",
    "color_thres= [[115 ,115 ,115],[145,145 ,145],[100 ,100 ,100],[150 ,150 ,150]]\n",
    "for each_img in glob.glob('./TestSet/*.png'):\n",
    "    results={}\n",
    "    for itr_thres in color_thres:\n",
    "        img=cv2.imread(each_img)\n",
    "        img,mask,results[str(itr_thres)]=preprocess(img, thresh_value=itr_thres)\n",
    "    data.append([each_img.split('\\\\')[-1],analytic_txt(results)])\n",
    "#         cv2.imshow(\"img1\",img)\n",
    "#         cv2.imshow(\"mask\",mask)\n",
    "#         cv2.waitKey(0)\n",
    "#         cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['1.png', '_IL_IL___IL_IL_IL_IL_IL__IL_IL_IL__'],\n",
       " ['10.png', 'IL_IL_IL_'],\n",
       " ['11.png', '+___'],\n",
       " ['12.png', '+_L____L__'],\n",
       " ['13.png', '__IL_____IL_+SI_NG_E__N'],\n",
       " ['14.png', 'B_A_B__+IL_IL_'],\n",
       " ['15.png', ''],\n",
       " ['16.png', ''],\n",
       " ['17.png', ''],\n",
       " ['18.png', ''],\n",
       " ['19.png', ''],\n",
       " ['2.png', 'R_ESTMIL_LE+_+'],\n",
       " ['20.png', ''],\n",
       " ['21.png', ''],\n",
       " ['22.png', 'L_IL_'],\n",
       " ['23.png', ''],\n",
       " ['24.png', ''],\n",
       " ['25.png', ''],\n",
       " ['3.png', ''],\n",
       " ['4.png', 'IL_'],\n",
       " ['5.png', '_IL__'],\n",
       " ['6.png', '_'],\n",
       " ['7.png', 'IL_IL_IL_IL__IL_IL_IL_IL_IL__'],\n",
       " ['8.png', ''],\n",
       " ['9.png', 'N+_EL_U+_IL____']]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame(data,columns=['file_name','text'])\n",
    "print(df.head())\n",
    "\n",
    "df.to_excel(\"submission.xlsx\") #dataframe to excel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem Faced:\n",
    "\n",
    "1. Image Quality were affecting as each quality will be having different threshold values\n",
    "\n",
    "2. Charcter colors like black and white character\n",
    "\n",
    "3. Postion or angle of the sign-board\n",
    "\n",
    "4. Dimensions of the images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: \"+\" folder can further used to extract the each character by using Dilation method."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
